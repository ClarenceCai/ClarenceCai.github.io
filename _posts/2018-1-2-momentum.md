---
layout: post
title: Momentum
---

Last time professor asked me whether I know momentum or not. I said I have no idea what that is. But know I know.
# Momentum
---
There are 2 articles helping me understand the concept of **momentum** in neural network:

[Improving the way neural networks learn](http://neuralnetworksanddeeplearning.com/chap3.html)
>Stochastic gradient descent by backpropagation has served us well in attacking the MNIST digit classification problem. However, there are many other approaches to optimizing the cost function, and sometimes those other approaches offer performance superior to mini-batch stochastic gradient descent.

Momentum-based gradient descent is one of the variations on stochastic gradient descent.

[Why Momentum Really Works](https://distill.pub/2017/momentum/) 
Momentum dampens oscillations and speeds up the iterations, leads to faster convergence. It has the virtue of spped that gradient descent does not have.
